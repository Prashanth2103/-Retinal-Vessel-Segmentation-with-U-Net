{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a604a5",
   "metadata": {},
   "source": [
    "# Retinal Vessel Segmentation with U‑Net\n",
    "\n",
    "Full ETL, U‑Net model, training, evaluation, and Streamlit app generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf7b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from albumentations import Compose, Resize, Normalize, HorizontalFlip, RandomRotate90, ElasticTransform\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score, f1_score\n",
    "import pickle\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ETL & Dataset Definition\n",
    "class RetinalDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.images = sorted(os.listdir(img_dir))\n",
    "        self.transform = transform if transform is not None else Compose([\n",
    "            Resize(256, 256),\n",
    "            Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = (mask > 127).astype('float32')\n",
    "        augmented = self.transform(image=image, mask=mask)\n",
    "        return augmented['image'], augmented['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. U‑Net Model Definition\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.down1 = DoubleConv(n_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.down2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.down3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.down4 = DoubleConv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.bottleneck = DoubleConv(512, 1024)\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.conv4 = DoubleConv(1024, 512)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.conv3 = DoubleConv(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.conv2 = DoubleConv(256, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.conv1 = DoubleConv(128, 64)\n",
    "        self.final = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        p1 = self.pool1(d1)\n",
    "        d2 = self.down2(p1)\n",
    "        p2 = self.pool2(d2)\n",
    "        d3 = self.down3(p2)\n",
    "        p3 = self.pool3(d3)\n",
    "        d4 = self.down4(p3)\n",
    "        p4 = self.pool4(d4)\n",
    "        bn = self.bottleneck(p4)\n",
    "        up4 = self.up4(bn)\n",
    "        merge4 = torch.cat([up4, d4], dim=1)\n",
    "        c4 = self.conv4(merge4)\n",
    "        up3 = self.up3(c4)\n",
    "        merge3 = torch.cat([up3, d3], dim=1)\n",
    "        c3 = self.conv3(merge3)\n",
    "        up2 = self.up2(c3)\n",
    "        merge2 = torch.cat([up2, d2], dim=1)\n",
    "        c2 = self.conv2(merge2)\n",
    "        up1 = self.up1(c2)\n",
    "        merge1 = torch.cat([up1, d1], dim=1)\n",
    "        c1 = self.conv1(merge1)\n",
    "        return torch.sigmoid(self.final(c1))\n",
    "\n",
    "# Instantiate model\n",
    "model = UNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bdb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Loaders\n",
    "train_dataset = RetinalDataset('data/train/images', 'data/train/masks')\n",
    "val_dataset = RetinalDataset('data/val/images', 'data/val/masks')\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Training Loop\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, val_iou, val_dice = [], [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.to(device), masks.unsqueeze(1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    train_losses.append(epoch_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, ious, dices = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_loader:\n",
    "            imgs, masks = imgs.to(device), masks.unsqueeze(1).to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).cpu().numpy().flatten()\n",
    "            truth = masks.cpu().numpy().flatten()\n",
    "            ious.append(jaccard_score(truth, preds))\n",
    "            dices.append(f1_score(truth, preds))\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_iou.append(np.mean(ious))\n",
    "    val_dice.append(np.mean(dices))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_losses[-1]:.4f} - Val Loss: {val_losses[-1]:.4f} - IoU: {val_iou[-1]:.4f} - Dice: {val_dice[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd37d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Metrics Visualization\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.legend(); plt.title('Loss Curves')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(val_iou, label='IoU')\n",
    "plt.plot(val_dice, label='Dice')\n",
    "plt.legend(); plt.title('Validation Metrics')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e38fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save Model & Transform\n",
    "os.makedirs('models', exist_ok=True)\n",
    "torch.save(model.state_dict(), 'models/unet_retinal.pth')\n",
    "with open('models/transform.pkl', 'wb') as f:\n",
    "    pickle.dump(train_dataset.transform, f)\n",
    "print(\"Model and transform saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Generate Streamlit App File\n",
    "streamlit_code = \"\"\"import streamlit as st\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import pickle\n",
    "from __main__ import UNet\n",
    "\n",
    "# Load model\n",
    "model = UNet().to('cpu')\n",
    "model.load_state_dict(torch.load('models/unet_retinal.pth', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "# Load transform\n",
    "with open('models/transform.pkl', 'rb') as f:\n",
    "    transform = pickle.load(f)\n",
    "\n",
    "st.title(\"Retinal Vessel Segmentation\")\n",
    "\n",
    "uploaded = st.file_uploader(\"Upload a fundus image\", type=[\"png\",\"jpg\",\"jpeg\"])\n",
    "if uploaded is not None:\n",
    "    image = Image.open(uploaded).convert(\"RGB\")\n",
    "    img_np = np.array(image)\n",
    "    augmented = transform(image=img_np, mask=img_np)  # mask ignored\n",
    "    input_tensor = torch.unsqueeze(augmented['image'], 0)\n",
    "    with st.spinner(\"Segmenting...\"):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            mask = (torch.sigmoid(output)[0,0].numpy() > 0.5).astype('uint8')\n",
    "    st.image(image, caption='Original', use_column_width=True)\n",
    "    st.image(mask, caption='Segmented Vessels', use_column_width=True)\n",
    "\"\"\"\n",
    "with open('streamlit_retinal_app.py', 'w') as f:\n",
    "    f.write(streamlit_code)\n",
    "print(\"Streamlit app file generated: streamlit_retinal_app.py\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
